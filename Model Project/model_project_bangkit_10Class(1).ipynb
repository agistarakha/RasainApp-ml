{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agistarakha/RasainApp-ml/blob/develop/Model%20Project/model_project_bangkit_10Class(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Mount Drive"
      ],
      "metadata": {
        "id": "qf2hEmX4Lr-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VGE6y-yO8Q8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvwVR5lHA8q_"
      },
      "source": [
        "##Prepare the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import library"
      ],
      "metadata": {
        "id": "hohiSNLVL6cR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install tensorflowjs"
      ],
      "metadata": {
        "id": "_dn1B3JdDEdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import subprocess"
      ],
      "metadata": {
        "id": "QdMmnBxHJl-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy dataset from drive"
      ],
      "metadata": {
        "id": "LrFFZDjtL_Zo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cp -R /content/drive/MyDrive/indo_food_datasets/jadi/food-dataset-500 /content/"
      ],
      "metadata": {
        "id": "wNUyAEOMImvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzip file"
      ],
      "metadata": {
        "id": "JTevTdAxMgzp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnYP_HhYNVUK"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "# Extract the archive\n",
        "local_zip = './food-dataset-500.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('tmp/food-dataset')\n",
        "zip_ref.close()\n",
        "\n",
        "# local_zip = './rps-test-set.zip'\n",
        "# zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "# zip_ref.extractall('tmp/rps-test')\n",
        "# zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Delete unused dataset"
      ],
      "metadata": {
        "id": "sK2avAZ9MYZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "food_classes = ['soto','pepes', 'mendoan', 'martabak', 'lumpia']\n",
        "\n",
        "for food_class in food_classes:\n",
        "  subprocess.run([\"rm\", \"-rf\", \"/content/food-dataset-500/test/\"+food_class])\n",
        "  subprocess.run([\"rm\", \"-rf\", \"/content/food-dataset-500/train/\"+food_class])"
      ],
      "metadata": {
        "id": "qmuG1kQ0JvNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "e5zXTZ02DpeI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Model Layer"
      ],
      "metadata": {
        "id": "wqNVPExuj7kR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgvGg2nsCj-0"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "    # This is the first convolution\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    # The fourth convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    #tf.keras.layers.Dropout(0.5),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile Model"
      ],
      "metadata": {
        "id": "2L-Ma2-8j_NA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OskuZ2ThFqmg"
      },
      "outputs": [],
      "source": [
        "# Set the training parameters\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer= tf.keras.optimizers.Adam() , metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ps7kIRaFRIC"
      },
      "source": [
        "## Prepare the ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWTisYLQM1aM"
      },
      "outputs": [],
      "source": [
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "TRAINING_DIR = \"/content/food-dataset-500/train\"\n",
        "training_datagen = ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "\t    rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "VALIDATION_DIR = \"/content/food-dataset-500/test\"\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_generator = training_datagen.flow_from_directory(\n",
        "\tTRAINING_DIR,\n",
        "\ttarget_size=(150,150),\n",
        "\tclass_mode='categorical',\n",
        "  batch_size=126\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "\tVALIDATION_DIR,\n",
        "\ttarget_size=(150,150),\n",
        "\tclass_mode='categorical',\n",
        "  batch_size=126\n",
        "  #batch_size=126\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Orf1QQlGGyOe"
      },
      "source": [
        "## Train the model and evaluate the results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Callback"
      ],
      "metadata": {
        "id": "r_6RE3TJjiSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    '''\n",
        "    Halts the training after reaching 60 percent accuracy\n",
        "\n",
        "    Args:\n",
        "      epoch (integer) - index of epoch (required but unused in the function definition below)\n",
        "      logs (dict) - metric results from the training epoch\n",
        "    '''\n",
        "\n",
        "    # Check accuracy\n",
        "    # if(logs.get('loss') < 0.4):\n",
        "\n",
        "    #   # Stop if threshold is met\n",
        "    #   print(\"\\nLoss is lower than 0.4 so cancelling training!\")\n",
        "    #   self.model.stop_training = True\n",
        "    if(logs.get('val_accuracy') > 0.75 and logs.get('accuracy') > 0.75):\n",
        "      # Stop if threshold is met\n",
        "      print(\"\\nVal_accuracy is higher than 0.8 so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "# Instantiate class\n",
        "callbacks = myCallback()"
      ],
      "metadata": {
        "id": "OO18Hxd82wVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Model"
      ],
      "metadata": {
        "id": "MWZo455CkJap"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mHX5L7HFXQ7"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_generator, epochs=50, validation_data = validation_generator, verbose = 1, validation_steps=3, callbacks=[callbacks])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the Graph history"
      ],
      "metadata": {
        "id": "-uKa0TvzjrH2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeTRVCr6aosw"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the results\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3ps8Q1tpYMG"
      },
      "source": [
        "# Model Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZABJp7T3VLCU"
      },
      "outputs": [],
      "source": [
        "## CODE BLOCK FOR NON-SAFARI BROWSERS\n",
        "## SAFARI USERS: PLEASE SKIP THIS BLOCK AND RUN THE NEXT ONE INSTEAD\n",
        "\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = fn\n",
        "  img = image.load_img(path, target_size=(150, 150))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  print(fn)\n",
        "  print(classes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "saved_model_path = \"./saved_model/{}.h5\".format(int(time.time()))\n",
        "\n",
        "model.save(saved_model_path)"
      ],
      "metadata": {
        "id": "4Pw5WROPCOjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorflowjs_converter --input_format=keras {saved_model_path} ./saved_model/js/"
      ],
      "metadata": {
        "id": "O0lh3tOpCSF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r model.zip saved_model"
      ],
      "metadata": {
        "id": "CpZJF8h_Dpqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHRufhQYJJLU"
      },
      "source": [
        "## Finish"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "model project bangkit.ipnyb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}